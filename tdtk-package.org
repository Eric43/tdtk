* Trauma director tool kit 

The goal of this org document is to put the initial public release of
the trauma director tool kit (TDTK) into a basic org document for
later reference. The initial minimal viable product release is done
with minimal functions designed for basic cleaning and data
analysis. The main package and R files are located on a GitHub
repository:  (https://github.com/Eric43/tdtk.  These function can be
used alone or in conjunction with tdtk markdown and example R files to
help with patient analysis.  The functions currently comprise of:


* Overall design justification for R based trauma patient data analysis

The goal of this document is to look at the main reasons for
=======
* Overall design justificaiton for R based trauma patiant data analysis

The goal of this document is to look at the main resons for
>>>>>>> bf9c6e7343d6d20b1068ab03e3cf083ac090a7fe
development of the trauma director tool kit (tdtk)
(https://github.com/Eric43/tdtk)

* Reasons for development

<<<<<<< HEAD
From ACS Orange book (primary resource for trauma directors):
=======
From ACS orage book (primary resource for trauma directors):
>>>>>>> bf9c6e7343d6d20b1068ab03e3cf083ac090a7fe

#+BEGIN_QUOTE
"A trauma registry can be valuable only if the data it contains can
be transformed into useful information through the process of report
writing. Trauma registry reports support decision making and guide the
management of the trauma center. Most trauma registry software
provides for the generation of several standard reports that summarize
different ways to address specific questions or areas of concern. Most
standard reports are oriented to anticipate the needs of a trauma
centerâ€™s PIPS program and provide the needed information. This
capability should be built into the software itself or achieved by
exporting the data to a separate spreadsheet, relational database, or
statistical program." (ACS orange book chapter 15)
#+END_QUOTE


** Need for a multi EHR/EMR platform trauma patient analysis software

Currently there are basic National Trauma Database (NTB) and Trauma
Quality Improvement Process (?) (TQUIP) summary analysis that allow
<<<<<<< HEAD
for basic bench marking.  This can provide trauma surgeons (defined as:
Advanced practice Surgeons with added credentials in Trauma and/or
Critical Care), with a broad overview of their trauma practice.
However, the use of large data sets and national/international
bench marking is not without problems.  First, this can lead to know
statistical effect such as Simpson's paradox (Yule-Simpson effect).
Next, while very useful for macro-patientomics disease analysis large
bench marking may obscure local/micro-patientomics disease patterns.
Finally, there is a need for a rapidly customized way for trauma
doctors to analyze their patient data in a customize and insightful
way.  Therefore, the use of R (a GNU licensed statistical
"programming" software) along with tdtk-package and markdown reports
form the basis of the tdtk ecosystem.

** Need for non-standard statistical analysis

As machine learning/artificial intelligence (ML/AI) increase in usage
it seems necessary that these models be applied to the disease of
trauma.  Some of the current non-standard summary statistical models
include (but are only limited by imagination):  linear modeling LOS to
ISS, Multi-group LM of LOS v ISS, multi-variate  analysis using linear
=======
for basic benchmarking.  This can provide trauma surgeons (defined as:
Adavanced ractice Surgeons with added creditials in Trauma and/or
Critical Care), with a broad overview of thier trauma practice.
However, the use of large data sets and national/international
benchmarking is ont without problems.  First, thic can lead to know
statistical effect such as Simpson's paradox (Yule-Simpson effect).
Next, whlle very useful for maco-patientomics disease analysis large
benchmarking may obscure local/micro-patientomics disease patterns.
Finally, there is a need for a rapidly customizable way for trauma
doctors to analyze their patient data in a customizable and insightful
way.  Therefore, the use of R (a GNU licensed statsitical
"programming" software) along with tdtk-package and markdown reports
form the basis of the tdtk ecosystem.

** Need for non-standard statisitcal analysis

As machine learning/artificial intellegence (ML/AI) increase in usage
it seems necessary that these models be applied to the disease of
trauma.  Some of the current non-standard summary statistical models
include (but are only limited by imagination):  linear modeling LOS to
ISS, Multi-group LM of LOS v ISS, muti-variate  analysis using linear
>>>>>>> bf9c6e7343d6d20b1068ab03e3cf083ac090a7fe
modeling for better estimation of resources needed to care for the
critically injured patient.  

** Need for local geo-spatial statistics 



** Need for ability to import .csv, .xls or SQL interface

** Need for common use statistical analysis platform for trauma directors

Looking at both federal, state and local trauma reports there is a
<<<<<<< HEAD
range of different analysis along with a range of different software
packages.  While each one of these statistical packages is an
incredible program there is cost of entry, cost to write specific
programs for the proprietary software and learning curve for each
of these systems.  Additionally, most (if not all) of the EHR/EMR
systems have basic SQL (or eq.) report generation abilities.  All of
these options provide a need for a free trauma specific statistical
analysis software that can interface either directly or via a file.

=======
range of different analysis along with a range of differnt software
packages such as: Mathematical, SAS, SPSS, MatLab etc.  While each one is an
incredible program in thier own right, there is are the monetary and
learning barrier of these systems.  Additionally, most (if not all) of
the EHR/EMR systems have basic SQL (or eq.) report generation
abilities.  All of these options provide a need for a free trauma
specific statistical analysis software.  
>>>>>>> bf9c6e7343d6d20b1068ab03e3cf083ac090a7fe

* Functions Overview

-  age_cat() DONE
-  blind_tdtk() TODO was part of read_tdtk but separating for ease of
   use.
-  ctr2cir() DONE
-  center2circle() DONE
-  disp_cat() DONE (basic) Dispensation cats derived from limited subset
- icd_cat() DONE (basic) ICD categories based on text needs updating 
- iss_cat() DONE Used standard referenced ISS bins
- read_tdtk() DONE in testing for xls or csv.  Added xls
   functionality.
- route2center() TODO goal is to use zip or obscured addresses to
  overlay all of the "estimated" routes and plot alpha level/N as a
  way to find commonly traveled routes etc.
- zip_clean() DONE (basic) derived from a limited subset need to
  rewrite using regex and extract the necessary run of 5 0...9.



In addition to the tdtk-package a collection of R functions, there are
markdown/R-markdown and later book down files for the development of
individualized dynamic documents (Refs).  The initial goal of the
markdown files is to provide a basic context to analyze trauma
patient data.  These data analysis are broken into sections/chapters
currently sections are defined as:

- Data loading/cleaning
- Data summary standard summary stats analysis
- Scatter plots of county or regional data
- Geo-spatial analysis of patient distribution
  + Trauma center service area in relationships to other centers
  + Individual data points with noise 
  + 2d density 

- Linear modeling for LOS 
  + With or without mortality
  + sub-grouped based upon standardized ISS categorizes
  + Predictive within historically established model
  + Can be used for Quality improvement for patients with longer LOS
    than expected.

- ARIMA
  + Modeling without seasonal correction.
  + Convolution of ARIMA data with seasonal effects
  + auto.arima() and prediction functions to look at expectation for
    patient numbers on a time series.

- Categorization Modeling
  + Basic random forest model looking for morbidity/mortality
    categorization.
  + Basic PCA looking a factor reduction in complex data sets
  + Later look at adding neural network model looking at
    procedures/timing of procedures as indicator of outcomes. (One ref
    on RNN (?) on diagnosis codes).

* Project needs/TODO list

** tdtk-package

This is the section of the todo lists on the tdtk-package.  This will
be used for tracking needs and what id done.

*** GitHub
    The GitHub tdtk public repo has been created and the functions have
    been "cleaned" of identifying/specific variable name calls
    (i.e. general calls of "patient_data" versus "<hospital name>_data".

**** DONE [#A] load and create the package using the package subdir.
     The goal of this is to have a separate working package directory
     in GitHub so that the subdir = "package" using the install_GitHub
     in devtools. Done in Jan 2019 and then pulled/deleted because
     didn't change all variable names (ewo).  Recreate repo and load ASAP.

*** Functions

**** DONE [#C] Finish spell checking core functions
     This was done on 31Jan2019 for basic functions need to repeat on
     the DESCRIPTION and other entries.

**** DONE [#A] Separate the read function into a less complicated mess
     Did the basic separation need to develop blind and other
     ancillary functions

**** DONE [#A] Finish the tdtk_blind function
     This was included as part of the read_tdtk() and made it
     difficult to use and higher probability of
     errors/warnings/stops.  Therefore separating the read and the
     blind functions. 
 
**** DONE [#A] Finish "compiling" the package 
     Due to the fact the laptop is does not have enough free space for
     necessary devtools andsupporting programs the tdtk-package needs
     to be completed on "Rainbow candycane" (not my first choice of
     name).

**** DONE [#B] Look at package req.
     Finalize the necessary packages included determine minimum
     necessary instead of library(tidyverse) try to do the necessary
     subset of this library (i.e. instad of all of tidyverse for map
     function just use purrr or if plotting just use ggmap2....etc. ad
     nauseum).

*** Documentation
    The current tdtk-package is using roxygen2 package to generate the
    manual/documentation etc. 

**** DONE [#C] Read and edit the documentation
     Once I finish with my edits send to sdm for a fresh set of eyes.
     Plus he can deconvolute my wriitng.

**** TODO [#C] Get the necessary references/cross-refs
     The documentation usng roxygen2 need to add the necessary laTeX
     references and link to the necessary 

**** DONE [#C] Check on the DESCRIPTION file
     Its either the desc or aother file but need to see if I'm
     correctly referencing the necesary packages.  I was on the ggmap
     GitHub site and didnt' have similar calls as they did for the
     required libraries. 

**** DONE [#C] See if I need to add a seperate .LICENSE file  
     Using GPL-v3 for license.  I think that only the MIT licensed
     needs to be added seperate and GitHub seems to have the GPLv3
     text added to the tdtk repo.


*** Data
    The current dataset for tdtk is limited and not validiated.  This
    needs to be changed to allow for testing and necessary background
    for trauma professionals to use during data analysis.

**** TODO [#A] ICD look uptable (CT)
     Currently only using a set of unique ICD text descriptions based
     upon a small sample size.  Need to full dataset.

**** TODO [#A] Trauma Center data set (CT)
     Collecting the national ACS and state trauma centers in a
     standard .csv or .xls document to be included in the DATASET to
     allow for testing and analysis by end users.

**** DONE [#C] Testing .csv of WV and SE regions TC
     Waiting for the necessary trauma center names etc was taking too
     long so did quick sample of the ACS and some state datasets. WV
     was used due to the fact its a full ACS state with level I
     through III centers with enough eperation to help troublshoot the
     circle functions.

**** TODO Reference table upload(CT) 
     Need to maintain the necessary references to aid in the
     development and authorship of the tdtk.  Currently waiting on
     anyform of reference manager (see references section).  Suggested
     JabRef for cross platform but anything that can be exported into
     similar or org.ref are needed.


**** TODO Design a function to fully randomize ezisting data
There needs to be a way to further de-identify data to allow for use
as a training set.  Best option is to randomize column data and then
fully randomized the rows.

*** References

**** TODO Complete the R references    
Need to get the entire list of R librarys used. This could not be done
without the Core team, Hadley Wickham and a ton of others
(G. Groleomond, GGMAP author, Xi (?) bookdown and others)

**** TODO Complete background non-clinical references

**** TODO Get any and all references from clinical team
     Need to get the references from the clinical team and use for
     necessay references to the functions and papers.
    



